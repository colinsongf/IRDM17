{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "training_path = r\"..\\data\\train.csv\"\n",
    "descriptions_path = r\"..\\data\\product_descriptions.csv\"\n",
    "attributes_path = r\"..\\data\\attributes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filepath:str, table:str):\n",
    "    if table == 'train':\n",
    "        result = []\n",
    "        with open(filepath, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',', quotechar='\"')  \n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                instance = {'id':row[0],'product_uid':row[1],'product_title':row[2],'search_term':row[3],\n",
    "                            'relevance':float(row[4])}\n",
    "                result.append(instance)\n",
    "    elif table == 'product_descriptions':\n",
    "        result = {}\n",
    "        with open(filepath, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',', quotechar='\"')  \n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                result[row[0]] = row[1]\n",
    "    elif table == 'attributes':\n",
    "        result = defaultdict(list)\n",
    "        with open(filepath, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',', quotechar='\"')  \n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                result[row[0]].append((row[1],row[2]))\n",
    "    return result\n",
    "\n",
    "def common_subsequence(doc1, doc2):\n",
    "    result = []\n",
    "    d1 = doc1.split(' ')\n",
    "    d2 = doc2.split(' ')\n",
    "    \n",
    "    d2_dict = OrderedDict()\n",
    "    \n",
    "    for word in d2:\n",
    "        d2_dict[word] = word\n",
    "    \n",
    "    for word in d1:\n",
    "        if word in d2_dict:\n",
    "            result.append(word)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def training_example_id(query_doc_pair:dict,feat_dict:dict):\n",
    "    feat_dict.update({'id':query_doc_pair['id']})\n",
    "\n",
    "#Feature: common subsequence between query and title\n",
    "#Arguments:\n",
    "#query_doc_pair is dictionary containing a row from the train.csv table, where they keys are the column names\n",
    "#description is a string containing the product description\n",
    "#attributes is list containing all (name,value) tuples for the product\n",
    "#feat_dict is a Dict(), which contains feature name-value pairs for other features extracted from\n",
    "#the same document-query pair. Basically, we will update that dictionary with a new feature.\n",
    "def feat_1(query_doc_pair:dict,description:str,attributes:list,feat_dict:dict):\n",
    "    query = query_doc_pair['search_term']\n",
    "    title = query_doc_pair['product_title']\n",
    "    subsequence = common_subsequence(query,title)\n",
    "    result = ' '.join(subsequence)\n",
    "    feat_dict.update({'subsequence_query+title':result})\n",
    "\n",
    "#Feature: common subsequence between query and description\n",
    "#Arguments:\n",
    "#query_doc_pair is dictionary containing a row from the train.csv table, where they keys are the column names\n",
    "#description is a string containing the product description\n",
    "#attributes is list containing all (name,value) tuples for the product\n",
    "#feat_dict is a Dict(), which contains feature name-value pairs for other features extracted from\n",
    "#the same document-query pair. Basically, we will update that dictionary with a new feature.\n",
    "def feat_2(query_doc_pair:dict,description:str,attributes:list,feat_dict:dict):\n",
    "    query = query_doc_pair['search_term']\n",
    "    subsequence = common_subsequence(query,description)\n",
    "    result = ' '.join(subsequence)\n",
    "    feat_dict.update({'subsequence_query+description':result})    \n",
    "    \n",
    "#Feature: all product attributes\n",
    "#Arguments:\n",
    "#query_doc_pair is dictionary containing a row from the train.csv table, where they keys are the column names\n",
    "#description is a string containing the product description\n",
    "#attributes is list containing all (name,value) tuples for the product\n",
    "#feat_dict is a Dict(), which contains feature name-value pairs for other features extracted from\n",
    "#the same document-query pair. Basically, we will update that dictionary with a new feature.\n",
    "def feat_3(query_doc_pair:dict,description:str,attributes:list,feat_dict:dict):    \n",
    "    temp_dict = {}\n",
    "    for attr in attributes:\n",
    "        temp_dict[attr[0]] = attr[1]\n",
    "        \n",
    "    feat_dict.update(temp_dict)\n",
    "    \n",
    "#Feature 4: number of words in common between the query and the attributes,\n",
    "#Feature 5: words in common between the query and the attribute\n",
    "#Arguments:\n",
    "#query_doc_pair is dictionary containing a row from the train.csv table, where they keys are the column names\n",
    "#description is a string containing the product description\n",
    "#attributes is list containing all (name,value) tuples for the product\n",
    "#feat_dict is a Dict(), which contains feature name-value pairs for other features extracted from\n",
    "#the same document-query pair. Basically, we will update that dictionary with a new feature.\n",
    "def feat_4_5(query_doc_pair:dict,description:str,attributes:list,feat_dict:dict):\n",
    "    query = set(query_doc_pair['search_term'].split(' '))\n",
    "    \n",
    "    all_words = set()\n",
    "    \n",
    "    for attr in attributes:\n",
    "        all_words.update(set(attr[0].split(' ')))\n",
    "        all_words.update(set(attr[1].split(' ')))\n",
    "        \n",
    "    common_words = query.intersection(all_words)\n",
    "    \n",
    "    \n",
    "    if len(common_words) == 0:\n",
    "        feat_dict.update({'common_word_count':0})\n",
    "        return\n",
    "    \n",
    "    temp_dict = {}\n",
    "    temp_dict['common_word_count'] = len(common_words)\n",
    "    for w in common_words:\n",
    "        temp_dict['common_word:'+w] = True\n",
    "        \n",
    "    feat_dict.update(temp_dict)\n",
    "\n",
    "def process_event(product,description,attributes):\n",
    "    feat_dict = {}\n",
    "    feat_1(product,description,attributes,feat_dict)\n",
    "    feat_2(product,description,attributes,feat_dict)\n",
    "    feat_3(product,description,attributes,feat_dict)\n",
    "    feat_4_5(product,description,attributes,feat_dict)\n",
    "    return feat_dict\n",
    "\n",
    "#Extracts features for all query-document pairs and returns a list of dictionaries, where each dictionary contains\n",
    "#the features for each doc-query pair.\n",
    "def feature_extraction(train:list,product_descriptions:dict,attibutes:dict):\n",
    "    all_features = []\n",
    "    for item in train:\n",
    "        product_uid = item['product_uid']\n",
    "        description = product_descriptions[product_uid]\n",
    "        attributes_list = attributes[product_uid]\n",
    "        all_features.append(process_event(item,description,attributes_list))\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = load_data(training_path,'train')\n",
    "product_descriptions = load_data(descriptions_path,'product_descriptions')\n",
    "attributes = load_data(attributes_path,'attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feat = feature_extraction(train, product_descriptions, attributes)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
