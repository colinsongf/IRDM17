{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9daa8cc116de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_path = r\"/home/jovyan/work/Desktop/Desktop/UCL/IRDM/data/joined_data.csv\"\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_stem(s):\n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = s.replace(\",\",\"\") #could be number / segment later\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"//\",\"/\")\n",
    "        s = s.replace(\"..\",\".\")\n",
    "        s = s.replace(\" / \",\" \")\n",
    "        s = s.replace(\" \\\\ \",\" \")\n",
    "        s = s.replace(\".\",\" . \")\n",
    "        s = re.sub(r\"(^\\.|/)\", r\"\", s)\n",
    "        s = re.sub(r\"(\\.|/)$\", r\"\", s)\n",
    "        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "        s = s.replace(\" x \",\" xbi \")\n",
    "        s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = s.replace(\"*\",\" xbi \")\n",
    "        s = s.replace(\" by \",\" xbi \")\n",
    "        s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "        s = s.replace(\"Â°\",\" degrees \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "        s = s.replace(\" v \",\" volts \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = s.replace(\" . \",\" \")\n",
    "        #s = (\" \").join([z for z in s.split(\" \") if z not in stop_w])\n",
    "        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"toliet\",\"toilet\")\n",
    "        s = s.replace(\"airconditioner\",\"air conditioner\")\n",
    "        s = s.replace(\"vinal\",\"vinyl\")\n",
    "        s = s.replace(\"vynal\",\"vinyl\")\n",
    "        s = s.replace(\"skill\",\"skil\")\n",
    "        s = s.replace(\"snowbl\",\"snow bl\")\n",
    "        s = s.replace(\"plexigla\",\"plexi gla\")\n",
    "        s = s.replace(\"rustoleum\",\"rust-oleum\")\n",
    "        s = s.replace(\"whirpool\",\"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolga\", \"whirlpool ga\")\n",
    "        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#relevance\n",
    "def feat_1(rows:list, feat_dict):\n",
    "    feat_dict.update({'relevance:':float(rows[0][0])})\n",
    "\n",
    "#search term\n",
    "def feat_2(rows:list, feat_dict):\n",
    "    feat_dict.update({'search term:': rows[0][2]})\n",
    "\n",
    "#product description - bag of words\n",
    "def feat_3(rows:list, feat_dict):\n",
    "    bag_of_words = default_dict(int)    \n",
    "    stemmed = [str_stem(w) for w in rows[0][4].split(' ')]\n",
    "    for word in stemmed:\n",
    "        bag_of_words[word] += 1\n",
    "        \n",
    "    temp_dict = {}\n",
    "    for k,v in bag_of_words.items():\n",
    "        temp_dict['description:' + k] = v\n",
    "    \n",
    "    feat_dict.update(temp_dict)\n",
    "\n",
    "#attributes\n",
    "def feat_4(rows:list, feat_dict):\n",
    "    temp_dict = {}\n",
    "    for row in rows:\n",
    "        temp_dict[row[5]] = row[6]\n",
    "        \n",
    "    feat_dict.update(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(filepath):  \n",
    "    data = []\n",
    "    id = -1\n",
    "    event = []\n",
    "    \n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')  \n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            #Accumulate all the rows with the same ID\n",
    "            if int(row[0]) != id:\n",
    "                #process event and add it to the events list\n",
    "                if len(event) > 0:\n",
    "                    instance = {}\n",
    "                    feat_1(event,instance)\n",
    "                    feat_2(event,instance)\n",
    "                    feat_3(event,instance)\n",
    "                    feat_4(event,instance)\n",
    "                    data.append(instance)\n",
    "                    event.clear()\n",
    "                    id = int(row[0])\n",
    "                    event.add(row)\n",
    "            else:\n",
    "                event.add(row)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_data(data:list):\n",
    "    vectorizer = DictVectorizer()\n",
    "    event_x = vectorizer.transform(data)\n",
    "    return event_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "training_data = load_data(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Vectorizer')\n",
    "vectorized_data = vectorize_data(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts labels into integers, and vice versa, needed by scikit-learn.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# encodes feature dictionaries as numpy vectors, needed by scikit-learn.\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "args = {\"feat_1\": True, \"feat_2\": True,\"feat_3\": True,\"feat_4\": True,\"feat_5\": True,\"feat_6\": True, \\\n",
    "\"feat_7\": True,\"feat_8\": True, \"feat_9\": True,\"feat_10\": False, \"feat_11\": True, \"feat_12\": True, \"feat_13\": True}\n",
    "\n",
    "def event_feat(event):\n",
    "    \"\"\"\n",
    "    This feature function returns a dictionary representation of the event candidate. You can improve the model \n",
    "    by improving this feature function.\n",
    "    Args:\n",
    "        event: the `EventCandidate` object to produce a feature dictionary for.\n",
    "    Returns:\n",
    "        a dictionary with feature keys/indices mapped to feature counts.\n",
    "\n",
    "    result = defaultdict(float)\n",
    "    result['trigger_word=' + event.sent.tokens[event.trigger_index]['word']] += 1.0\n",
    "    return result\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    #Feature 1: trigger word stem\n",
    "    if args[\"feat_1\"]:\n",
    "        feat_1(event, result)\n",
    "    #Feature 2: trigger word capitalization\n",
    "    if args[\"feat_2\"]:\n",
    "        feat_2(event, result)\n",
    "    #Feature 3: trigger word has digits?\n",
    "    if args[\"feat_3\"]:\n",
    "        feat_3(event, result)\n",
    "    #Feature 4: trigger word has punctuation?\n",
    "    if args[\"feat_4\"]:\n",
    "        feat_4(event, result)\n",
    "    #Feature 5: trigger word bigrams and trigrams\n",
    "    if args[\"feat_5\"]:\n",
    "        feat_5(event, result)\n",
    "    #Feature 6: probable classes according to training data\n",
    "    if args[\"feat_6\"]:\n",
    "        feat_6(event, result) \n",
    "    #Feature 7: number of entities\n",
    "    if args[\"feat_7\"]:\n",
    "        feat_7(event, result)\n",
    "    #Feature 8: bag of words\n",
    "    if args[\"feat_8\"]:\n",
    "        feat_8(event, result)\n",
    "    #Feature 9: distance to closest protein?\n",
    "    if args[\"feat_9\"]:\n",
    "        feat_9(event, result)\n",
    "    #Feature 10: all trigger features of 3 prev and 3 following neighbours\n",
    "    if args[\"feat_10\"]:\n",
    "        feat_10(event, result)\n",
    "    #Feature 11: all token features for the dependency chain tokens of a depth of 3, and sequence of dependencies\n",
    "    if args[\"feat_11\"]:\n",
    "        feat_11(event, result)\n",
    "    #Feature 12: shortest path to nearest protein\n",
    "    if args[\"feat_12\"]:\n",
    "        feat_12(event, result)\n",
    "    #Feature 13: PoS tag\n",
    "    if args[\"feat_13\"]:\n",
    "        feat_13(event, result)       \n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def predict_event_labels(event_candidates):\n",
    "    \"\"\"\n",
    "    This function receives a list of `bio.EventCandidate` objects and predicts their labels. \n",
    "    It is currently implemented using scikit-learn, but you are free to replace it with any other\n",
    "    implementation as long as you fulfil its contract.\n",
    "    Args:\n",
    "        event_candidates: A list of `EventCandidate` objects to label.\n",
    "    Returns:\n",
    "        a list of event labels, where the i-th label belongs to the i-th event candidate in the input.\n",
    "    \"\"\"\n",
    "    event_x = vectorizer.transform([event_feat(e) for e in event_candidates])\n",
    "    event_y = label_encoder.inverse_transform(lr.predict(event_x))\n",
    "    return event_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
